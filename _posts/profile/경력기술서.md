# 나의 경력 기술서 (2023-05-14 기준)

---

## 외부 저장매체 반입 검사 시스템의 중앙관리 시스템 백엔드 개발

- 제품명 : GateXcanner

- 제품 개발 인원 : 3명

- 담당 역할 : GateXcanner 중앙관리시스템 백엔드 개발

- 담당 서비스 개발 인원 : 1명

- 기술 스택 : **java, spring boot, elasticsearch, nginx, azure devops pipeline, docker**

- 운영 방식 : 온프라미스

### 프로젝트 소개

외부 저장매체 반입 시 악성코드를 포함하고있는 외부 저장매체에 대한 사전 차단을 목표로 개발된 GateXcanner 서비스의 중앙관리 시스템이 존재하였으나 낙후되었으며 유지보수가 되어있지 않아 많은 버그 와 기능 미지원등일 발생하여 웹 기반의 새로운 중앙관리 시스템의 필요가 시급하여 개발을 진행하였습니다.

#### 주요 기능

- KIOSK 장비 실시간 상태 관리 API
- KIOSK 사용 정책 관리 API
- KIOSK 장비 감사 로그 관리 API
- 사용자 및 역할 관리 API
- 사용자 감사 로그 관리 API
- 외부 저장매체 검사 결과 로그 관리 API
- 알림 API

### 개발 핵심 소개

- 공통적인 비즈니스 코드 간소화
- Elasticsearch 를 활용한 빠른 로그 검색
- 클라우드 제품만 CI/CD? NO! 온프라미스도 CI/CD 구축
- 온프라미스 제품에 대한 사내 최초 도커 테스트환경 구축
- 버저닝 자동화를 위한 Gradle 버저닝 플러그인 제작

#### 공통적인 비즈니스 코드 간소화

개발 단계에서 대부분의 REST API 들이 간단한 CRUD 의 비즈니스 로직을 갖고 있기에 공통화를 통한 비즈니스 코드 간소화가 가능해 보였습니다.

BaseService, BaseDao 를 만들어서, 공통된 로직들을 모으고 이를 상속받아 활용하는 방안으로 했습니다.
이를 위해서는 필수 불가결하게 Base로직을 사용하기위한 전처리 및 후처리 작업들이 필요하게 되었는데,

이를 위해서 **Spring AOP**를 적극 활용하여 DTO, Entity 객체 내부의 필드들에 Custom Annotation 들을 지정해주어 로직 전,후 작업들이 진행되도록 하였습니다. (예 : 특정 값에 대한 Insert 및 update 시 알림 발생, API 호출자 역할에 따른 매타데이터 삽입 등, 한번 등록 후 변경하면 안되는 필드에 대한 변경 시도 검증 등)

그 결과 비즈니스 코드가 간소화 되고 역할을 명확히 분리할 수 있었습니다.

#### Elasticsearch 를 활용한 빠른 로그 검색

설계 단계에서 운영 로그, 감사 로그, 검사 로그 등 로그성 데이터들의 대량 적재가 예상되어
사용자 검색 시 "키워드" 검색 기능이 들어가면 검색 속도가 느려질 것이 우려되었습니다.

이를 개선하고자 **검색 엔진인 Elasticsearch를 도입**하여 운영 로그, 검사 로그, 감사 로그 등을 저장하였으며

역색인을 기반으로한 빠른 키워드 검색이 가능하게 되었습니다.

> **잠깐! : Elasticsearch 도입시 발생한 문제들**
> Elasticsearch 도입시 해당 기술에 대한 지식이 충분히 학습 되어있지 않은 상태였으며, 이에 따라 관계형 데이터베이스에 적재해야할 데이터들과 Elasticsearch에 적재해야할 데이터의 명확한 분리가 되지 않음
> 그 결과 관계형 데이터들을 Elastcsearch에 적재하는 불상사가 발생하여 곤혹을 치룬 경험이 존재함
> 관계형 데이터베이스를 사용해야할 데이터를 Elasticsearch에 저장했을 때 발생하는 문제점 들 **join 미지원, 빈번한 수정이 발생하는 데이터에 대한 속도 저하, 트랜잭션 미지원, deep paging 불가** 등

#### 클라우드 제품만 CI/CD? NO! 온프라미스도 CI/CD 구축

제품이 첫 릴리즈되고 난 후 고객사가 굉장히 많아지면서 고객별 커스텀 기능 요구사항도 상당히 많아졌습니다.

어떤 고객사는 완전 자신들위해서 제품을 전반적으로 뜯어고치길 바랬으며, 어떤 고객사는 사소하지만 상당히 많은 범위에서 자잘하게 수정을 요구하였습니다.

이런 고객사들이 점차 많아지면서 하루에도 수차례 수정 및 배포가 진행되는 상황이 발생하였는데, 이를 로컬 빌드만으로는 감당이 안되는 상황이 발생하였습니다.

이를 해결하고자 사내 Task 관리를 위해 사용 중인 **Azure Devops** 의 **Build pipeline, Release pipeline** 기능을 적극 활용하였습니다.

사내 온프라미스 제품 배포시 사내 NAS 에서 엔지니어 분들이 설치 패키지를 직접 USB에 담아서 고객사로 반입하여 설치하는 절차를 갖고 있었으며,

사내 NAS와의 연동을 위해 cloud 빌드 서버가 아닌 **azure self hosted build agent** 를 직접 사내에 구축하였으며 이에 **사내 NAS를 마운팅** 하여 빌드 시 사내 NAS에 접근할 수 있도록 구성하였습니다.

Build pipeline 과 Release pipeline 의 역할을 철저히 구분하여

**Build pipeline** 에서는 **PullRequest 검증, 실제 Build 및 버저닝 자동화** 를 진행했으며,
**Release pipeline** 에서는 온프라미스기 제품이기 때문에 **빌드 결과물 사내 NAS 업로드, 테스트를 위한 도커 이미지 제작 및 도커 레지스트리에 이미지 업로드** 등을 진행하였습니다.

#### 온프라미스 제품에 대한 사내 최초 도커 테스트환경 구축

위 "클라우드 제품만 CI/CD? NO! 온프라미스도 CI/CD 구축" 에도 잠시 나왔던 도커가 사용된 이유는
실제 고객사 배포시에는 도커를 사용하지 않지만, 사내에서 배포를 위해서는 기능 수정시 마다 테스트를 진행해야하는데 고객사마다 커스텀된 기능이 너무 많기에 **기능 하나 수정시 마다 고객사마다 테스트가 필요** 했습니다.

일반 적인 도커 이미지의 경우 컨테이너 하나에 서비스 하나를 올려서 MSA 를 따라가지만
실제 운영 목적이 아닌 **고객사 별 서비스 테스트** 가 목적이기 때문에 **하나의 이미지에 서비스를 위한 모든 서비스 설치** 하는 방식이며, **Release pipeline** 에서 고객사별 정보를 주입받아 이미지 빌드 시 고객사에 맞게 config 가 수정되어 이미지가 빌드되는 방식으로 진행하였습니다.

위 작업으로 인하여 테스트시에 컨테이너 실행만으로 고객사별 환경을 간단하게 생성할 수 있게 되었습니다.

#### 버저닝 자동화를 위한 Gradle 버저닝 플러그인 제작

Azure Build pipeline 에서 간단하게 버저닝이 가능해야했기 때문에 pipeline에서 빌드 시 쉽게 버저닝을 할 수 있도록 별도의 gradle 버저닝 플러그인을 제작하였습니다.

개인 프로젝트에서도 필요하여 이미 개발하고 있었으며 이를 가져다 사용했습니다.

아직은 0.0.1 로 사실상 배타 버전이지만 버저닝 자체는 가능하기에 이를 사용하였습니다.

제작된 플러그인은 **gradle 공식 plugin repo에 등록**하였으며 간단하게 사용할 수 있습니다.

**github 링크 : https://github.com/mainmethod0126/simple-semantic-version**
**gradle plugin repo 링크 : https://plugins.gradle.org/plugin/io.github.mainmethod0126.simple-semantic-version**

버저닝은 시맨틱 버저닝을 채택하였으며, gradle build 명령어로 간단하게 버저닝 가능하게 만들었습니다.

---

## 원격 근무 PC화면 로깅 제품의 로그 적재 및 조회 서비스 백엔드 개발

- 제품명 : Screen Logger

- 제품 개발 인원 : 2명

- 담당 역할 : Screen Logger 로그 적재 및 조회 서비스 백엔드 개발

- 담당 서비스 개발 인원 : 1명

- 기술 스택 : **java, spring boot, elasticsearch, kafka, protocol buffer, snappy, nginx, azure devops pipeline**

- 운영 방식 : 온프라미스

### 프로젝트 소개

코로나 시대에 재택근무 시장이 활성화되며 근무중인 회사에서도 보안을 강조한 재택근무 솔루션을 개발하게 되었으며, 재택근무시 발생할 수 있는 사내 보안문서 유출, 비양심적 근무 태만 등을 방지하기 위하여 사용자가 PC의 화면을 주기적으로 또는 특정 이벤트를 감지 (마우스 클릭, 특정 키보드 키 입력) 하여 캡쳐하고 캡쳐된 이미지에 **광학 문자 인식(OCR)** 작업을 진행하여 텍스트를 추출 및 영속화하여 관리자가 언제든 검색을 통하여 근무자의 화면 이미지 및 화면상의 텍스트 등을 감시할 수 있도록 하는 서비스입니다.

#### 주요 기능

- 키워드를 통한 화면 캡쳐 로그 검색 API
- 사용자 정보를 통한 화면 캡쳐 로그 검색 API

### 개발 핵심 소개

- kafka 를 활용한 elasticsearch 이중화
- kafka 를 활용한 로그 데이터 손실 방지
- protocol buffer 와 snappy 를 활용한 데이터 전송 최적화
- protocol buffer 를 활용한 개발 간소화
- 공통적인 비즈니스 코드 간소화 (타 프로젝트와 중복되어 자세한 내용 생략)
- Elasticsearch 를 활용한 빠른 로그 검색 (타 프로젝트와 중복되어 자세한 내용 생략)
- 클라우드 제품만 CI/CD? NO! 온프라미스도 CI/CD 구축 (타 프로젝트와 중복되어 자세한 내용 생략)
- 버저닝 자동화를 위한 Gradle 버저닝 플러그인 제작 (타 프로젝트와 중복되어 자세한 내용 생략)

#### kafka 를 활용한 elasticsearch 이중화

elasticsearch 라는 서비스는 기본적으로 **홀수개의 노드로 클러스터링** 이라는 원칙이 깔려있습니다.
하지만 제품을 구매하는 고객은 **두대의 서버로 이중화** 를 요구하였고 이를 수용하기 위해서 **kafka** 를 도입하였습니다.

각 서버에 kafka를 설치한 후 서버당 Kafka Consumer 를 두개씩 생성하고 하나의 Counsumer는 자기자신의 Topic을, 다른 하나의 Consumer는 대응되는 서버의 Topic을 구독하게하여, 대응되는 서버에 들어온 데이터를 똑같이 쌓는 방법을 개발하였습니다

이러면 하나의 서버가 Down되어도 나머지 하나의 서버가 Down된 서버에 있는 데이터와 같은 데이터들을 가지고 있으니 검색되는 정보의 손실이 발생하지 않습니다.

#### kafka 를 활용한 로그 데이터 손실 방지

대량의 데이터가 동시다발적으로 서버에 요청되면, 일반적인 서블릿 기반 서비스는 가용할 수 있는 쓰레드 범위를 넘어서면 신규 요청들이 무시되는 상황이 발생합니다.

이렇게 되면 클라이언트에서 Request 실패시 저장 후 나중에 재시도 라는 로직을 넣어 놓지 않게되면 해당 요청은 소실되게 됩니다.

서버가 언제 정상적으로 요청을 처리할 수 있을 지 모르는 상황에서 클라이언트에 계속해서 데이터를 쌓는 다는 것도 문제가 됩니다.

이때 서버측에서 들어오는 데이터를 수용하되 요청에 대한 Queue를 파일기반으로 저장할 수 있도록 하면이를 해결할 수 있습니다.

이런한 목적으로 파일 기반 Message Queue인 kafka 를 도입하여 사용자의 Request를 최대한 수용하고, 갑작스러운 서버 Down등의 문제에서 파일이라는 영속화 데이터로 안전하게 서비스를 운영할 수 있도록 하였습니다

#### protocol buffer 와 snappy 를 활용한 데이터 전송 최적화

OCR의 결과는 화면상에 보이는 Text 이며 현재 사용자의 화면에 따라 상당히 많은 텍스트가 존재할 수 있고
이러한 텍스트를 대규모의 접속자가 동시다발적으로 네트워크를 통해 전달한다는 것은 네트워크적인 부하를 예상할 수 있습니다.

이를 해결하고자 첫번째로 **protocol buffer** 를 사용했습니다.
**protocol buffer** 란 구글이 개발한 **직렬화 데이터 구조** 이며, 일반적으로 직렬화 방식보다 더 작은 양의 데이터로 직렬화를 가능하게 해줍니다.

이를 통하여 전송되는 데이터의 크기를 일차적으로 줄였으며,
이에 더해 직렬화된 데이터를 **snappy** 라는 구글이 개발한 **압축 라이브러리** 를 통하여 직렬화된 데이터를 압축, 이차적으로 데이터를 줄였습니다.

이렇게 최적화된 데이터 전송을 통하여 네트워크 부하를 줄인 서비스를 구성하였습니다.

#### protocol buffer 를 활용한 개발 간소화

**protocol buffer** 는 직렬화라는 장점도 존재하지만 또 하나의 특별한 장점이 존재합니다.
**.proto** 라는 형식의 파일을 통하여 언어에 종속되지 않는 사용이 가능하다는 점 입니다.
이 .proto 파일만 공유할 수 있다면, 누구든지 protocol buffer 컴파일러를 사용하여 자신이 사용하고자 하는 언어에 맞는 객체를 생성할 수 있습니다.

이 장점을 통하여 특정 서비스와 통신해야하는 서비스의 경우 어떤 형식으로 데이터를 구성해서 전달해야하는지 고민할 필요없이 .proto 파일만 공유받아 자신이 사용하고자하는 언어로 컴파일하여 사용하면 간단합니다.

이를 통하여 코드 작업량을 줄일 수 있으며, 실제로 참여했던 프로젝트의 적은 인원으로도 프로젝트 기한을 준수할 수 있었습니다.

