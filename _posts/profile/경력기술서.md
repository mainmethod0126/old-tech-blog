# 나의 경력 기술서 (2023-05-14 기준)

---

## 외부 저장매체 반입 검사 시스템의 중앙관리 시스템 백엔드 개발

- 제품명 : GateXcanner

- 개발 인원 : 1명

- 담당 역할 : GateXcanner 중앙관리시스템 백엔드 개발

- 기술 스택 : **java, spring boot, elasticsearch, nginx, azure devops pipeline, docker**

- 운영 방식 : 온프라미스

### 프로젝트 소개

외부 저장매체 반입 시 악성코드를 포함하고있는 외부 저장매체에 대한 사전 차단을 목표로 개발된 GateXcanner 서비스의 중앙관리 시스템이 존재하였으나 낙후되었으며 유지보수가 되어있지 않아 많은 버그 와 기능 미지원등일 발생하여 웹 기반의 새로운 중앙관리 시스템의 필요가 시급하여 개발을 진행하였습니다.

#### 주요 기능

- KIOSK 장비 실시간 상태 관리 API
- KIOSK 사용 정책 관리 API
- KIOSK 장비 감사 로그 관리 API
- 사용자 및 역할 관리 API
- 사용자 감사 로그 관리 API
- 외부 저장매체 검사 결과 로그 관리 API
- 알림 API

### 개발 핵심 소개

- 공통적인 비즈니스 코드 간소화
- Elasticsearch 를 활용한 빠른 로그 검색
- 클라우드 제품만 CI/CD? NO! 온프라미스도 CI/CD 구축
- 온프라미스 제품에 대한 사내 최초 도커 테스트환경 구축
- 버저닝 자동화를 위한 Gradle 버저닝 플러그인 제작

#### 공통적인 비즈니스 코드 간소화

개발 단계에서 대부분의 REST API 들이 간단한 CRUD 의 비즈니스 로직을 갖고 있기에 공통화를 통한 비즈니스 코드 간소화가 가능해 보였습니다.

BaseService, BaseDao 를 만들어서, 공통된 로직들을 모으고 이를 상속받아 활용하는 방안으로 했습니다.
이를 위해서는 필수 불가결하게 Base로직을 사용하기위한 전처리 및 후처리 작업들이 필요하게 되었는데,

이를 위해서 **Spring AOP**를 적극 활용하여 DTO, Entity 객체 내부의 필드들에 Custom Annotation 들을 지정해주어 로직 전,후 작업들이 진행되도록 하였습니다. (예 : 특정 값에 대한 Insert 및 update 시 알림 발생, API 호출자 역할에 따른 매타데이터 삽입 등, 한번 등록 후 변경하면 안되는 필드에 대한 변경 시도 검증 등)

그 결과 비즈니스 코드가 간소화 되고 역할을 명확히 분리할 수 있었습니다.

#### Elasticsearch 를 활용한 빠른 로그 검색

설계 단계에서 운영 로그, 감사 로그, 검사 로그 등 로그성 데이터들의 대량 적재가 예상되어
사용자 검색 시 "키워드" 검색 기능이 들어가면 검색 속도가 느려질 것이 우려되었습니다.

이를 개선하고자 **검색 엔진인 Elasticsearch를 도입**하여 운영 로그, 검사 로그, 감사 로그 등을 저장하였으며

역색인을 기반으로한 빠른 키워드 검색이 가능하게 되었습니다.

> **잠깐! : Elasticsearch 도입시 발생한 문제들**
> Elasticsearch 도입시 해당 기술에 대한 지식이 충분히 학습 되어있지 않은 상태였으며, 이에 따라 관계형 데이터베이스에 적재해야할 데이터들과 Elasticsearch에 적재해야할 데이터의 명확한 분리가 되지 않음
> 그 결과 관계형 데이터들을 Elastcsearch에 적재하는 불상사가 발생하여 곤혹을 치룬 경험이 존재함
> 관계형 데이터베이스를 사용해야할 데이터를 Elasticsearch에 저장했을 때 발생하는 문제점 들 **join 미지원, 빈번한 수정이 발생하는 데이터에 대한 속도 저하, 트랜잭션 미지원, deep paging 불가** 등

#### 클라우드 제품만 CI/CD? NO! 온프라미스도 CI/CD 구축

제품이 첫 릴리즈되고 난 후 고객사가 굉장히 많아지면서 고객별 커스텀 기능 요구사항도 상당히 많아졌습니다.

어떤 고객사는 완전 자신들위해서 제품을 전반적으로 뜯어고치길 바랬으며, 어떤 고객사는 사소하지만 상당히 많은 범위에서 자잘하게 수정을 요구하였습니다.

이런 고객사들이 점차 많아지면서 하루에도 수차례 수정 및 배포가 진행되는 상황이 발생하였는데, 이를 로컬 빌드만으로는 감당이 안되는 상황이 발생하였습니다.

이를 해결하고자 사내 Task 관리를 위해 사용 중인 **Azure Devops** 의 **Build pipeline, Release pipeline** 기능을 적극 활용하였습니다.

사내 온프라미스 제품 배포시 사내 NAS 에서 엔지니어 분들이 설치 패키지를 직접 USB에 담아서 고객사로 반입하여 설치하는 절차를 갖고 있었으며,

사내 NAS와의 연동을 위해 cloud 빌드 서버가 아닌 **azure self hosted build agent** 를 직접 사내에 구축하였으며 이에 **사내 NAS를 마운팅** 하여 빌드 시 사내 NAS에 접근할 수 있도록 구성하였습니다.

Build pipeline 과 Release pipeline 의 역할을 철저히 구분하여

**Build pipeline** 에서는 **PullRequest 검증, 실제 Build 및 버저닝 자동화** 를 진행했으며,
**Release pipeline** 에서는 온프라미스기 제품이기 때문에 **빌드 결과물 사내 NAS 업로드, 테스트를 위한 도커 이미지 제작 및 도커 레지스트리에 이미지 업로드** 등을 진행하였습니다.

#### 온프라미스 제품에 대한 사내 최초 도커 테스트환경 구축

위 "클라우드 제품만 CI/CD? NO! 온프라미스도 CI/CD 구축" 에도 잠시 나왔던 도커가 사용된 이유는
실제 고객사 배포시에는 도커를 사용하지 않지만, 사내에서 배포를 위해서는 기능 수정시 마다 테스트를 진행해야하는데 고객사마다 커스텀된 기능이 너무 많기에 **기능 하나 수정시 마다 고객사마다 테스트가 필요** 했습니다.

일반 적인 도커 이미지의 경우 컨테이너 하나에 서비스 하나를 올려서 MSA 를 따라가지만
실제 운영 목적이 아닌 **고객사 별 서비스 테스트** 가 목적이기 때문에 **하나의 이미지에 서비스를 위한 모든 서비스 설치** 하는 방식이며, **Release pipeline** 에서 고객사별 정보를 주입받아 이미지 빌드 시 고객사에 맞게 config 가 수정되어 이미지가 빌드되는 방식으로 진행하였습니다.

위 작업으로 인하여 테스트시에 컨테이너 실행만으로 고객사별 환경을 간단하게 생성할 수 있게 되었습니다.

#### 버저닝 자동화를 위한 Gradle 버저닝 플러그인 제작

Azure Build pipeline 에서 간단하게 버저닝이 가능해야했기 때문에 pipeline에서 빌드 시 쉽게 버저닝을 할 수 있도록 별도의 gradle 버저닝 플러그인을 제작하였습니다.

개인 프로젝트에서도 필요하여 이미 개발하고 있었으며 이를 가져다 사용했습니다.

아직은 0.0.1 로 사실상 배타 버전이지만 버저닝 자체는 가능하기에 이를 사용하였습니다.

제작된 플러그인은 **gradle 공식 plugin repo에 등록**하였으며 간단하게 사용할 수 있습니다.

**github 링크 : https://github.com/mainmethod0126/simple-semantic-version**
**gradle plugin repo 링크 : https://plugins.gradle.org/plugin/io.github.mainmethod0126.simple-semantic-version**

버저닝은 시맨틱 버저닝을 채택하였으며, gradle build 명령어로 간단하게 버저닝 가능하게 만들었습니다.

---

## 원격 근무 PC화면 로깅 서비스 백엔드 개발

- 제품명 : Screen Logger

- 개발 인원 : 2명

- 담당 역할 : Screen Logger 로그 적재 및 조회 서비스 백엔드 개발

- 기술 스택 : **java, spring boot, elasticsearch, kafka, nginx, azure devops pipeline**

- 운영 방식 : 온프라미스

### 프로젝트 소개

코로나 시대에 재택근무 시장이 활성화되며 근무중인 회사에서도 보안을 강조한 재택근무 솔루션을 개발하게 되었으며, 재택근무시 발생할 수 있는 사내 보안문서 유출, 비양심적 근무 태만 등을 방지하기 위하여 사용자가 PC의 화면을 주기적으로 또는 특정 이벤트를 감지 (마우스 클릭, 특정 키보드 키 입력) 하여 캡쳐하고 캡쳐된 이미지에 **광학 문자 인식(OCR)** 작업을 진행하여 텍스트를 추출 및 영속화하여 관리자가 언제든 검색을 통하여 근무자의 화면 이미지 및 화면상의 텍스트 등을 감시할 수 있도록 하는 서비스입니다.

#### 주요 기능

- 키워드를 통한 화면 캡쳐 로그 검색 API
- 사용자 정보를 통한 화면 캡쳐 로그 검색 API

### 개발 핵심 소개

- kafka 를 활용한 elasticsearch 이중화
- kafka 를 활용한 로그 데이터 손실 방지
- protocol buffer 를 활용한 데이터 전송 최적화
- protocol buffer 를 활용한 개발 간소화
- 공통적인 비즈니스 코드 간소화 (타 프로젝트와 중복되어 자세한 내용 생략)
- Elasticsearch 를 활용한 빠른 로그 검색 (타 프로젝트와 중복되어 자세한 내용 생략)
- 클라우드 제품만 CI/CD? NO! 온프라미스도 CI/CD 구축 (타 프로젝트와 중복되어 자세한 내용 생략)
- 버저닝 자동화를 위한 Gradle 버저닝 플러그인 제작 (타 프로젝트와 중복되어 자세한 내용 생략)

#### kafka 를 활용한 elasticsearch 이중화

elasticsearch 라는 서비스는 기본적으로 **홀수개의 노드로 클러스터링** 이라는 원칙이 깔려있습니다.
하지만 제품을 구매하는 고객은 **두대의 서버로 이중화** 를 요구하였고 이를 수용하기 위해서 **kafka** 를 도입하였습니다.

각 서버에 kafka를 설치한 후 서버당 Kafka Consumer 를 두개씩 생성하고 하나의 Counsumer는 자기자신의 Topic을, 다른 하나의 Consumer는 대응되는 서버의 Topic을 구독하게하여, 대응되는 서버에 들어온 데이터를 똑같이 쌓는 방법을 개발하였습니다

이러면 하나의 서버가 Down되어도 나머지 하나의 서버가 Down된 서버에 있는 데이터와 같은 데이터들을 가지고 있으니 검색되는 정보의 손실이 발생하지 않습니다.